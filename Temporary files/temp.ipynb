{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import html\n",
    "import re\n",
    "import random\n",
    "import json\n",
    "\n",
    "\n",
    "def find_one(html_str, pattern_str):\n",
    "    \"\"\"\n",
    "    find one attr value in element\n",
    "    like title, year, rating, duration, gross\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    html_str : str\n",
    "    pattern_str : str\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str or np.nan\n",
    "    \"\"\"\n",
    "    match = re.search(pattern_str, html_str)\n",
    "    if match:\n",
    "        return html.unescape(match.group(1))\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def find_many(html_str, pattern_str):\n",
    "    \"\"\"\n",
    "    find many attr value in element\n",
    "    like genres, urls, names, duration\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    html_str : str\n",
    "    pattern_str : str\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "    \"\"\"\n",
    "    match = re.findall(pattern_str, html_str)\n",
    "    if match:\n",
    "        return html.unescape(match)\n",
    "    else:\n",
    "        []\n",
    "\n",
    "\n",
    "def create_specific_dict(name_list, url_list, pattern_str):\n",
    "    \"\"\"\n",
    "    Specifically, it concatenates two lists and creates a dictionary\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    name_list : list\n",
    "    url_list : list\n",
    "    pattern_str : str\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "    \"\"\"\n",
    "    result_dict = {}\n",
    "    for url, name in zip(url_list, name_list):\n",
    "        match = re.search(pattern_str, url)\n",
    "        if match:\n",
    "            url = match.group(1)\n",
    "        else:\n",
    "            url = np.nan\n",
    "        result_dict[name] = url\n",
    "    return result_dict\n",
    "\n",
    "\n",
    "def find_url_id_title(html_str, pattern_str):\n",
    "    url_pattern = r\"/title/tt(\\d+)\"\n",
    "\n",
    "    matches = re.search(pattern_str, html_str)\n",
    "    if matches:\n",
    "        url = matches.group(1)\n",
    "        title = matches.group(2)\n",
    "\n",
    "    title = html.unescape(title)\n",
    "    url = url.split(\"/\")\n",
    "    url = \"/\".join(url[:-1])\n",
    "\n",
    "    match = re.search(url_pattern, url)\n",
    "    if match:\n",
    "        id = match.group(1)\n",
    "    else:\n",
    "        id = np.nan\n",
    "\n",
    "    return url, id, title\n",
    "\n",
    "\n",
    "def find_story_line(url, headers):\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        story_line = response.json()\n",
    "        story_line = story_line[\"data\"][\"title\"][\"summaries\"][\"edges\"][0][\"node\"][\n",
    "            \"plotText\"\n",
    "        ][\"plaidHtml\"]\n",
    "        story_line = html.unescape(story_line)\n",
    "        return story_line\n",
    "    print(\"Failed to fetch the website.\", response.status_code)\n",
    "    return -1\n",
    "\n",
    "\n",
    "user_agents = [\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36\"\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36\"\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36\"\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36\"\n",
    "    \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36\"\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.1 Safari/605.1.15\"\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 13_1) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.1 Safari/605.1.15\"\n",
    "]\n",
    "\n",
    "story_line_url0 = \"https://caching.graphql.imdb.com/?operationName=TMD_Storyline&variables=%7B%22isAutoTranslationEnabled%22%3Afalse%2C%22locale%22%3A%22en-US%22%2C%22titleId%22%3A%22\"\n",
    "story_line_url2 = \"%22%7D&extensions=%7B%22persistedQuery%22%3A%7B%22sha256Hash%22%3A%22ad739d75c0062966ebf299e3aedc010e17888355fde6d0eee417f30368f38c14%22%2C%22version%22%3A1%7D%7D\"\n",
    "\n",
    "url = \"https://www.imdb.com/chart/top/?ref_=nv_mv_250\"\n",
    "main_url = \"https://www.imdb.com\"\n",
    "headers = {\n",
    "    \"User-Agent\": random.choice(user_agents),\n",
    "    \"Accept-Language\": \"en-US,en;q=0.5\",\n",
    "}\n",
    "story_line_headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}\n",
    "\n",
    "title_link_pattern = r'<a class=\"ipc-title-link-wrapper\" href=\"(/title/tt\\d+/\\?ref_=chttp_t_\\d+)\" tabindex=\"\\d+\"><h3 class=\"ipc-title__text\">(\\d+\\.\\s+.+)</h3></a>'\n",
    "title_pattern = r'<span class=\"sc-afe43def-1 fDTGTb\">(.*?)</span>'\n",
    "year_pattern = r'href=\"/title/tt\\d+/releaseinfo\\?ref_=tt_ov_rdat\" role=\"button\" tabindex=\"0\">(\\d+)</a>'\n",
    "rating_pattern = r'href=\"/title/tt\\d+/parentalguide/certificates\\?ref_=tt_ov_pg\" role=\"button\" tabindex=\"0\">(.*?)</a>'\n",
    "# duration_pattern = r'role=\"presentation\">(\\d+h \\d+m)</li>'\n",
    "# duration_pattern = r'role=\"presentation\">(\\d+h(?: \\d+m)?)</li>'\n",
    "duration_pattern = r'role=\"presentation\">(\\d+h(?: \\d+m)?|(\\d+m))</li>'\n",
    "genres_pattern = r'<span class=\"ipc-chip__text\">(.*?)</span>'\n",
    "dr_url_pattern = r'href=\"(/name/nm\\d+/\\?ref_=tt_ov_dr)\"'\n",
    "wr_url_pattern = r'href=\"(/name/nm\\d+/\\?ref_=tt_ov_wr)\"'\n",
    "st_url_pattern = r'href=\"(/name/nm\\d+/\\?ref_=tt_ov_st)\"'\n",
    "name_pattern = r\"<a.*?>(.*?)</a>\"\n",
    "gross_label_pattern = r'class=\"ipc-metadata-list-item__label\">(.*?)</span>'\n",
    "gross_value_pattern = r'class=\"ipc-metadata-list-item__list-content-item\">(.*?)</span>'\n",
    "id_in_url_pattern = r\"/name/nm(\\d+)/\\?ref_=tt_ov\"\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "if response.status_code == 200:\n",
    "    html_content = response.content\n",
    "else:\n",
    "    print(\"Failed to fetch the website.\")\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"dict_id\",\n",
    "        \"title\",\n",
    "        \"year\",\n",
    "        \"parental_guide\",\n",
    "        \"runtime\",\n",
    "        \"genre\",\n",
    "        \"directore\",\n",
    "        \"writer\",\n",
    "        \"star\",\n",
    "        \"storyline\",\n",
    "        \"gross_us_canada\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "title_link_elements = soup.find(\n",
    "    \"ul\",\n",
    "    attrs={\n",
    "        \"class\": \"ipc-metadata-list ipc-metadata-list--dividers-between sc-3f13560f-0 sTTRj compact-list-view ipc-metadata-list--base\"\n",
    "    },\n",
    ").find_all(\"a\", attrs={\"class\": \"ipc-title-link-wrapper\"})\n",
    "# title_link_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "for element in title_link_elements:\n",
    "    cnt = cnt + 1\n",
    "    # if cnt > 21:\n",
    "    #     break\n",
    "\n",
    "    movie_url, movie_id, movie_name = find_url_id_title(\n",
    "        str(element), title_link_pattern\n",
    "    )\n",
    "    temp_dict = {}\n",
    "    temp_dict[movie_id] = movie_name\n",
    "    url = main_url + movie_url\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        html_content = response.content\n",
    "    else:\n",
    "        print(\"Failed to fetch the website.\")\n",
    "        print(cnt)\n",
    "        break\n",
    "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "    # class=\"ipc-overflowText ipc-overflowText--pageSection ipc-overflowText--base\" --> Storyline\n",
    "    tyrd_element = soup.find(\n",
    "        \"div\", attrs={\"class\": \"sc-dffc6c81-0 iwmAVw\"}\n",
    "    )  # element for title, year, rating, duration\n",
    "    genres_element = soup.find(\"div\", attrs={\"class\": \"ipc-chip-list__scroller\"})\n",
    "    name_url_elements = soup.find_all(\n",
    "        \"div\", attrs={\"class\": \"ipc-metadata-list-item__content-container\"}\n",
    "    )\n",
    "    gross_element = soup.find(\n",
    "        \"li\",\n",
    "        attrs={\n",
    "            \"class\": \"ipc-metadata-list__item sc-6d4f3f8c-2 byhjlB\",\n",
    "            \"data-testid\": \"title-boxoffice-grossdomestic\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "    movie_title = find_one(str(tyrd_element), title_pattern)\n",
    "    release_year = find_one(str(tyrd_element), year_pattern)\n",
    "    movie_rating = find_one(str(tyrd_element), rating_pattern)\n",
    "    movie_duration = find_one(str(tyrd_element), duration_pattern)\n",
    "    genres = find_many(str(genres_element), genres_pattern)\n",
    "\n",
    "    dr_url = find_many(str(name_url_elements[0]), dr_url_pattern)\n",
    "    dr_name = find_many(str(name_url_elements[0]), name_pattern)\n",
    "    dr_dict = create_specific_dict(dr_name, dr_url, id_in_url_pattern)\n",
    "\n",
    "    wr_url = find_many(str(name_url_elements[1]), wr_url_pattern)\n",
    "    wr_name = find_many(str(name_url_elements[1]), name_pattern)\n",
    "    wr_dict = create_specific_dict(wr_name, wr_url, id_in_url_pattern)\n",
    "\n",
    "    st_url = find_many(str(name_url_elements[2]), st_url_pattern)\n",
    "    st_name = find_many(str(name_url_elements[2]), name_pattern)\n",
    "    st_dict = create_specific_dict(st_name, st_url, id_in_url_pattern)\n",
    "\n",
    "    # gross_label = find_one(str(gross_element), gross_label_pattern)\n",
    "    gross_value = find_one(str(gross_element), gross_value_pattern)\n",
    "\n",
    "    parts = movie_url.split(\"/\")\n",
    "    if len(parts) > 2:\n",
    "        story_line_url1 = parts[2]\n",
    "    else:\n",
    "        print(\"can't find\")\n",
    "        print(cnt)\n",
    "        break\n",
    "    storyline = find_story_line(\n",
    "        story_line_url0 + story_line_url1 + story_line_url2, story_line_headers\n",
    "    )\n",
    "\n",
    "    new_row = {\n",
    "        \"dict_id\": temp_dict,\n",
    "        \"title\": movie_title,\n",
    "        \"year\": release_year,\n",
    "        \"parental_guide\": movie_rating,\n",
    "        \"runtime\": movie_duration,\n",
    "        \"genre\": genres,\n",
    "        \"directore\": dr_dict,\n",
    "        \"writer\": wr_dict,\n",
    "        \"star\": st_dict,\n",
    "        \"storyline\": storyline,\n",
    "        \"gross_us_canada\": gross_value,\n",
    "    }\n",
    "    df.loc[len(df)] = new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"250_top_IMDB.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
